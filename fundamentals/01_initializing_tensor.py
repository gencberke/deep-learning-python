"""
1) Tensor nedir? (ve neden PyTorchâ€™un kalbidir)
2) Tensor Ã¶zellikleri (shape, dtype, device)
3) Tensor oluÅŸturma yollarÄ±
4) Tensorâ€™lar arasÄ±nda iÅŸlemler (ekleme, Ã§arpma, reshape)
5) Numpy ile fark ve dÃ¶nÃ¼ÅŸÃ¼m (array â†” tensor)
"""
from random import randint
import torch
import numpy as np

# reproducibility - her Ã§alÄ±ÅŸtÄ±rmada aynÄ± random sonuÃ§lar
torch.manual_seed(42)

print("===================================== 1) Tensor nedir?")
"""
1) Tensor nedir?

    Tensor PyTorch'taki core data typelardan biridir. aslÄ±nda cpu'da veya gpu'da yaÅŸayabilen Ã§ok boyutlu bir array'dir
(multi-dimensional array) ve autograd'i destekler deep learning iÃ§in. 

    A scalar -> tek sayÄ± (Ã¶rnek: 5)
    A vector -> tek boyutlu liste (Ã¶rnek: [1, 2, 3])
    A matrix -> iki boyutlu tablo (Ã¶rnek: [[1,2],[3,4]])
    A tensor -> bunlarÄ±n genelleÅŸtirilmiÅŸ halidir; 0, 1, 2, 3, â€¦ n boyutlu olabilir.
"""

# burada python listesini torch tensor objesine dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼k. yani artÄ±k Ã¼zerinde matematiksel
# iÅŸlemler yapÄ±lmasÄ±nÄ± destekliyor.
x = torch.tensor([[1, 2], [3, 4]])
print(x)

print("===================================== 2) Tensor Ã¶zellikleri:")

"""
2) Tensor Ã¶zellikleri:
"""
print(x.shape)  # tensorun boyutu (rows, columns)
print(x.dtype)  # veri tipi (Ã¶rnek: int64 veya float32)
print(x.device)  # CPU mu GPU mu?
print(x.ndim)  # kaÃ§ boyutlu? (2D tensor)

print("===================================== 3) Tensor oluÅŸturma yollarÄ±:")

"""
3) Tensor oluÅŸturma yollarÄ±:
"""

# tÃ¼m elemanlarÄ± "sÄ±fÄ±r"'dan oluÅŸan 3 satÄ±r 4 sÃ¼tunluk bir tensor (multi-dimensional array)
zeros = torch.zeros((3, 4))

# tÃ¼m elemanlarÄ± "bir"'den oluÅŸan 3 satÄ±r 4 sÃ¼tunluk bir tensor (multi-dimensional array)
ones = torch.ones((3, 4))

# 0, 1 arasÄ± rastgele deÄŸerler Ã¼retir. her Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda farklÄ± sonuÃ§ Ã§Ä±karÄ±r
random_tensor = torch.rand((3, 4))
print(random_tensor)
# Rastgele normalize deÄŸerler Ã¼retmek

# -âˆ ile +âˆ arasÄ± deÄŸerler Ã¼retir, ortalama 0 civarÄ±nda daÄŸÄ±lÄ±r (Gaussian distribution)
# dikkat! yukarÄ±dakinden sadece bir harf farklÄ±: rand -> randn
random_tensor = torch.randn((3, 4))
print(random_tensor)
# Model initialization (Ã¶rneÄŸin weightâ€™ler) gibi yerlerde kullanÄ±lÄ±r

# verilen deÄŸerler arasÄ± rastgele int iÃ§erikli tensor Ã¼retir:
my_randint = torch.randint(low=0, high=5, size=(3, 4))
print(my_randint)

# step kadar arttÄ±rÄ±p end'e kadar gider (end hariÃ§tir)
a = torch.arange(start=0, end=30, step=3)

# start ve end arasÄ±nda eÅŸit aralÄ±klÄ± 10 deÄŸer Ã¼retir (end dahildir)
b = torch.linspace(start=0, end=30, steps=10)

print(a)
print(b)

"""
    Tensor oluÅŸtururken dtype ve device belirlenebilir. dtype tensorun data type'Ä±nÄ± temsil ederken device ise cpu'da mÄ±
gpuda mÄ± oluÅŸturulacaÄŸÄ±nÄ± temsil eder. bu Ã¶nemlidir Ã§Ã¼nkÃ¼ arada hem performans farkÄ± Ã§ok yÃ¼ksektir hem iki tensor arasÄ±
iÅŸlem yapÄ±lacaksa aynÄ± birimlerde depolanmasÄ± gerekmektedir. biz ÅŸimdilik cpu kullanÄ±caz. 
"""

x = torch.ones((3, 4), dtype=torch.float32, device='cpu')
print(x)

"""
    "cuda" yazdÄ±ÄŸÄ±nda GPUâ€™da oluÅŸturulur ama Ã¶nce torch.cuda.is_available() kontrolÃ¼ yapÄ±lmalÄ±.
"""
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
x = torch.rand((3, 3), device=device)
print(x.device)

print("===================================== 4) Tensor Operations:")

"""
4) Tensor Operations: 
"""

a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32, device='cpu')
b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32, device='cpu')

# â€œelement-wiseâ€ = her bir hÃ¼cre kendi karÅŸÄ±lÄ±ÄŸÄ±yla iÅŸlem gÃ¶rÃ¼r.
print(a + b)  # element-wise addition
print(a - b)  # element-wise subtraction
print(a * b)  # element-wise multiplication
print(a / b)  # element-wise division

# matrix multiplication (2x2 @ 2x2 -> 2x2)
# not: eÄŸer bu iÅŸlem vector'lar Ã¼zerinde yapÄ±lÄ±rsa buna dot product denir.
matmul_result = torch.matmul(a, b)
print(matmul_result)

# reshaping tensors: tensorun verisini deÄŸiÅŸtirmeden boyutlarÄ±nÄ± yeniden dÃ¼zenler
# Ã¶rneÄŸin iÃ§inde 12 deÄŸer olan bir matrisi 3x4 e reshapeleyebiliriz.
x = torch.arange(0, 12)
reshaped = x.reshape(3, 4)
print(reshaped)

print("===================================== *) Hot-Takes:")

"""
    1) numpy ve pytorch birbiriyle iletiÅŸimde olabilir.
"""

torch_tensor = torch.tensor([[1, 2], [3, 4]])
numpy_array = torch_tensor.numpy()  # torch tensor to -> numpy array
print(type(numpy_array), numpy_array)

numpy_array_second = np.array([[5, 6], [7, 8]])
torch_tensor_second = torch.from_numpy(numpy_array_second).float()  # numpy array to -> torch tensor
                                                                    # torch.from_numpy aynÄ± belleÄŸi paylaÅŸÄ±r yani numpy array deÄŸiÅŸirse
                                                                    # torch_tensor da deÄŸiÅŸir ama ayrÄ± nesneleri gÃ¶stersin istiyorsak
                                                                    # torch.tensor() ile yeni bir tensor yaratÄ±p ona numpy array'i kopyalarÄ±z
print(type(torch_tensor_second), torch_tensor_second)

"""
    2) bahsettiÄŸimiz gibi iki tensor Ã¶ÄŸesi arasÄ±nda iÅŸlem yapÄ±lacaksa bu ikisi aynÄ±
        birimde initialize edilmiÅŸ olmasÄ± gerekir. bir tensor'u taÅŸÄ±mak iÃ§in <tensor ismi>.to kullanÄ±labilir
"""
my_tensor = torch.tensor([[1, 2], [3, 4]])
my_tensor = my_tensor.to("cpu")  # my_tensor'u taÅŸÄ±mamÄ±z gerektiÄŸinde "<tensor ismi> = " yaparÄ±z yoksa kopyasÄ±nÄ±
# taÅŸÄ±r tensorun kendisini deÄŸil

"""
    3) tensor initialization shortcuts: 
"""
eye = torch.eye(3)  # birebir (identity) matris
full = torch.full((3, 3), 5)  # tÃ¼m elemanlarÄ± verilen fill_value olan matris
randn = torch.randn(3, 3)  # Gaussian daÄŸÄ±lÄ±mÄ±ndan rastgele sayÄ±lar (ortalama 0, varyans 1)

"""
    4) requires_grad=true nedir?
        bu ilerideki notlarda daha detaylÄ± incelenecek olsada backward progression yaparken iÅŸimize yarayacak.
        geÃ§miÅŸi hafÄ±zada tutmaya yarÄ±yacak. true'ya Ã§ekmediÄŸimiz sÃ¼rece geÃ§miÅŸi akÄ±lda tutmayacak. 
"""
x = torch.tensor([[2.0, 3.0]], requires_grad=True)
y = (x ** 2).sum()  # scalar output iÃ§in .sum() Ã§Ã¼nkÃ¼ backward yapmak iÃ§in tek dimension ÅŸimdilik
y.backward()
print(x.grad)  # gradient = 2*x yani tensor([[4., 6.]])

print("===================================== ğŸ“˜ Summary Table: Tensor Fundamentals")

"""
| Konsept | AÃ§Ä±klama | Ã–rnek Kod |
|----------|-----------|-----------|
| tensor | PyTorch'un temel veri yapÄ±sÄ± (multi-dimensional array). | x = torch.tensor([[1,2],[3,4]]) |
| shape / dtype / device | Boyut, veri tipi ve iÅŸlem birimi (CPU/GPU). | x.shape, x.dtype, x.device |
| tensor initialization | FarklÄ± tensor oluÅŸturma yollarÄ±. | torch.zeros(), torch.ones(), torch.rand() |
| random generation | Rastgele tensor Ã¼retir (uniform veya normal dist.). | torch.rand(), torch.randn() |
| arange / linspace | SayÄ± aralÄ±klarÄ±ndan tensor oluÅŸturur. | torch.arange(0,10,2), torch.linspace(0,1,5) |
| device placement | Tensorâ€™un CPU veya GPUâ€™da oluÅŸturulmasÄ±. | x.to("cuda") |
| numpy interoperability | NumPy array â†” Torch tensor dÃ¶nÃ¼ÅŸÃ¼mÃ¼. | t.numpy(), torch.from_numpy(a) |
| element-wise operations | TÃ¼m elemanlarda aynÄ± anda iÅŸlem yapar. | a + b, a * b |
| requires_grad | TÃ¼revi takip edip etmeyeceÄŸini belirler. | torch.tensor([1.0], requires_grad=True) |
"""
